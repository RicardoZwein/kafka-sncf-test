# ğŸš† Suivi en temps rÃ©el des retards des TER SNCF avec Kafka
*Ce projet est un exercice personnel et n'est pas affiliÃ© Ã  la SNCF.*

## ğŸ” Contexte
On me dit souvent que la SNCF a tendance Ã  Ãªtre en retard un peu trop souvent. Est-ce vrai, ou est-ce simplement un effet de saillance qui nous pousse Ã  remarquer davantage les retards que les trains Ã  lâ€™heure ? (Spoiler Alert, c'est bel et bien un effet de saillance !)

Dans le doute, je me suis dit que j'allais faire ce que je fais de mieux...Et m'amuser avec des donnÃ©es. 

On va setup un process qui permettrait de vÃ©rifier notre hypothÃ¨se, en prenant des donnÃ©es en temps rÃ©el de chez la SNCF ! 

Si on fait tourner ce projet assez longtemps sur une machine assez performante (ou si on prend simplement en compte les recommendations que j'ai posÃ©es en fin de projet pour une version plus optimisÃ©e), on peut rÃ©pondre Ã  cette question avec assez de dÃ©tail, mais les rÃ©sultats que j'ai obtenus Ã©taient dÃ©jÃ  intÃ©ressants.

J'ai pris le parti pris de faire un petit dashboard en "temps rÃ©el" (mis Ã  jour toutes les 2 minutes en raison des limites du GTFS-RT TU), histoire de pouvoir observer les Ã©volutions en temps rÃ©el.

<br>

## ğŸš€ Comment Ã§a marche ?

### 1ï¸âƒ£ Lancer lâ€™environnement Kafka

Avant tout, il faut dÃ©marrer **Kafka** et **Zookeeper.**\
Tout est dÃ©jÃ  configurÃ© dans **`docker-compose.yml`**, donc un simple :

```bash
docker-compose up -d
```

... et câ€™est parti ! Kafka tourne en tÃ¢che de fond.


### 2ï¸âƒ£ DÃ©marrer le Producteur

Le **producer** va envoyer des messages Kafka contenant les donnÃ©es de retard des trains en temps rÃ©el.

```bash
python producer.py
```

Ce script va rÃ©cupÃ©rer les mises Ã  jour **GTFS-RT** et les envoyer dans le topic **`sncf-realtime`**.


### 3ï¸âƒ£ DÃ©marrer le Consumer + Dashboard

Une fois les messages envoyÃ©s, il faut un **consumer** pour les traiter et les afficher.\
Lance-le avec :

```bash
python realtime_train_delays.py
```

Celui-ci :

- AgrÃ¨ge les donnÃ©es en **temps rÃ©el**
- Met Ã  jour un **dashboard en live** via **Plotly Dash**
- Affiche un **histogramme des retards actuels**

AccÃ¨de ensuite Ã  lâ€™interface via ton navigateur :

```
http://127.0.0.1:8050
```

*(Le lien s'affichera dans le Terminal au lancement du script.)*

<br>

## ğŸ“Š DonnÃ©es visualisÃ©es

âœ… **Retards en minutes**, classÃ©s par intervalles (`0`, `1-5`, `6-10`, etc.)\
âœ… **Mise Ã  jour toutes les 2 minutes** (frÃ©quence des messages Kafka)\
âœ… **Histogramme dynamique** qui Ã©volue en fonction des donnÃ©es entrantes

<br>

## ğŸ¢ Tech Stack

âš« **Kafka** pour la gestion des flux de donnÃ©es\
âš« **Docker** pour lâ€™orchestration\
âš« **Python** (`kafka-python`, `dash`, `plotly`, `pandas`, etc.)\
âš« **GTFS-RT** pour les donnÃ©es de transport en temps rÃ©el

<br>

## ğŸ¯ Objectif ?

Ce projet nâ€™a pas vocation Ã  Ãªtre utilisÃ© en production, mais sert Ã  dÃ©montrer comment Kafka peut Ãªtre utilisÃ© pour du traitement de flux en temps rÃ©el, et accessoirement, c'est un petit exercice qui m'a permis de me familiariser avec Kafka en dehors de lectures thÃ©oriques...!

<br>

## ğŸ“’ Et aprÃ¨s ?

- Actuellement, on rÃ©cupÃ¨re tous les retards, mais on pourrait affiner en **filtrant par gare, par exemple.**
- Ajouter un **stockage persistant** (commeÂ **PostgreSQL** ou **DuckDB**) pour historiser les retards.
- Pourquoi pas un **modÃ¨le de prÃ©diction** des retards Ã  partir des historiques ?

<br>

## ğŸ—ƒï¸ Data Source 
RÃ©seau national TER SNCF : https://transport.data.gouv.fr/datasets/horaires-des-lignes-ter-sncf
